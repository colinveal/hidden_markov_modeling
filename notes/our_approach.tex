\section{Our Approach}
In this section we describe the modeling approach we follow.
We begin by discussing the core elements behind Hidden Markov Models.
The discussion is taken from \cite{rabiner2009}

\subsection{Hidden Markov Model}
\label{hmm}

In this section we briefly describe the workings of Hidden Markov Models (HMM). We then proceed in discussing the application  of the model.


An HMM has the following core elements \cite{rocha2012}, \cite{rabiner2009}

\begin{itemize}
	\item $N$ the number of states in the model. The set of states is denoted by $S$. Hence, $S={S1,\cdots S_N}$ and $|S|=N$. At time $t$ the state is denoted as $s_t$.
	\item $M$ the number of distinct observation symbols per state.
	The observation symbols correspond to the physical output of the system that we model.
	\item The state transition probability matrix $A$ where
	\begin{equation}
	A_{i,j} = P(S_{t+1} = s_j | S_t=s_i)
	\label{transition_prob}
	\end{equation}
	\item Emission probabilities with $e_{i,\alpha}$ as the probability of emitting symbol $\alpha$ in state i with 
	$\sum_{\alpha \in A} e_{i}(\alpha) = 1$
	\item  Initial state probability $\pi = {\pi_i}$ as the probability of being at state $s_i$ at instant $t=0$; i.e.
	\begin{equation}
	\pi_i = P(S_i = s_1), 1 \leq i \leq N
	\label{initial_state}
	\end{equation} 
\end{itemize}

For the special case where any state can reach any other state in a single step we have that

\begin{equation}
A_{i,j} > 0, \forall i,j
\end{equation}

Given the appropriate values of $N, M, A, B$ and $\pi$ the HMM can be used as model for generating an observation sequence

\begin{equation}
O = O_1O_2\dots O_T
\end{equation}
Each observation $O_i \in V$ and $T$ is the number of observations in the sequence.

\begin{framed}
	\begin{enumerate}
		\item Choose an initial state $s_1$ according to $\pi$
		\item Choose $O_t$ according to the symbol probability when in state $S_i$ that is $e_{i,k}$
	\end{enumerate}
\end{framed}

The procedure above can be used as both a generator of the observations and as a model for how ta given observation sequence was generated by an appropriate HMM.

An HMM can be summarized by the vector

\begin{equation}
\lambda = (\pi, A, E)
\label{hmm_vector}
\end{equation}
that is the HMM is characterized by the initial state probabilities, the transition matrix $A$, and the emission probabilities $E$.

For an HMM in order to be useful one should be able to answer the 
following three questions \cite{rabiner2009}

\begin{enumerate}
	\item Given the observation sequence $O$ and a model $\lambda$, how can we compute $P(O|\lambda)$. This is the evaluation problem; given a model and a sequence of observations, how do we compute the probability that the observed sequence was produced by the model?
	\item Given the observation sequence $O$ and a model $\lambda$, how can we choose a corresponding state sequence $Q$ which best explains the observations?
	\item How do we adjust the model described by $\lambda$ to maximize $P(O|\lambda)$? This is the training problem.
\end{enumerate}

The three models are linked. Problem 1 can be solved using the forward-backward algorithm \cite{rabiner2009}. Problem 2 can be solved using the Viterbi algorithm whilst problem 3 can be solved using Baum-Welch algorithm \cite{rabiner2009}.

\subsection{HMM development}
\label{hmm_dev}

We are considering two samples for the same individual. One sample is undergoing WGA (sample m605) before sequencing. Sample m585 does not. From the produced sequenced data we then extract the region that corresponds to the chromosome 1. The extracted data is then aligned into non overlapping windows 
of length $L$. Reads of quality less than Q30 were rejected. 



A read is considered only if it satisfies a certain
quality threshold (The \mintinline{c++}{pysam} function \mintinline{c++}{get_query_qualities} which returns query base quality scores at pileup column position). The extracted RD data for each file is then fitted to a normal distribution
  
In our approach we assume that the system can be modelled using four states. Hence, the state set is

\begin{equation}
S = {\text{NORMAL}, \text{TUF}, \text{INSERTION}, \text{DELETION}}
\end{equation}

We can further refine the $S$ set following previous studies e.g.
\cite{coella2007} and \cite{Wang2007} where they assumed that the
$\text{NORMAL}$ state is better described by assuming separate states namely Normal heterozygote and Normal homozygote. 
Furthermore, we assume every state can lead to any other state.
Therefore currently we assume a fully connected model.
The observations set $V$ contains only the RD counts. Since the $\text{TUF}$ state mimics the $\text{DELETION}$ state when considering RD counts (i.e. reduced RD counts) we assume the following:

\begin{itemize}
	\item Regions of low RD observed in both files do not represent $\text{TUF}$ but rather $\text{DELETION}$?
	\item Regions of low RD observed in m605 that are $\text{NORMAL}$ in m585 are indicative of $\text{TUF}$.
\end{itemize}  

.


In our case, we have that the observations consists solely of RD counts. Furthermore, the set of states is the following



We assume the following


We want to fit the an HMM model with $K$ states to the vector of the observed RD counts. We can use the 



There are several items we need to clarify. 

\begin{itemize}
\item How do we initialize the transition probabilities?
\item How do we define the emission probabilities?
\item How do we differentiate between deletion and TUF as the latter mimics deletion in RD?
\end{itemize}


